version: "3.9"

name: ${COMPOSE_PROJECT_NAME:-voiceai}
services:
  backend:
    build:
      context: ./backend/Takeaway.Api
      dockerfile: Dockerfile
    container_name: voiceai-backend
    depends_on:
      - stt
      - tts
    environment:
      ASPNETCORE_ENVIRONMENT: "Development"
      ASPNETCORE_URLS: "http://+:8080"
      STT__BaseUrl: "http://stt:9090"
      TTS__BaseUrl: "http://tts:5000"
    volumes:
      - ./data:/app/data
    expose:
      - "8080"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 5

  stt:
    image: ghcr.io/rhasspy/asr-faster-whisper:latest
    container_name: voiceai-stt
    environment:
      HTTP_PORT: "9090"
      WHISPER_MODEL: "base"
    ports:
      - "9090:9090"
    volumes:
      - stt-models:/data

  tts:
    image: ghcr.io/rhasspy/tts-piper:latest
    container_name: voiceai-tts
    environment:
      HTTP_PORT: "5000"
      VOICE: "en_US-amy-medium"
    ports:
      - "5000:5000"
    volumes:
      - tts-voices:/data

  web:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: voiceai-web
    expose:
      - "80"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost/health"]
      interval: 10s
      timeout: 3s
      retries: 5
      
  caddy:
    build:
      context: ./reverse-proxy
      dockerfile: Dockerfile
    container_name: voiceai-proxy
    depends_on:
      - backend
      - web
    ports:
      - "${CADDY_HTTP_PORT:-80}:80"
      # Uncomment next line if you enable TLS in Caddyfile
      # - "${CADDY_HTTPS_PORT:-443}:443"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost/health"]
      # The proxy /health maps to backend in our Caddyfile; this asserts routing is OK.
      interval: 10s
      timeout: 3s
      retries: 5

volumes:
  stt-models:
  tts-voices: